{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hotel No-Show Analysis: Exploratory Data Analysis\n",
    "\n",
    "This notebook presents a comprehensive exploratory data analysis of the hotel chain's customer no-show data. The analysis aims to identify patterns and factors that influence customer no-shows, which will inform the development of predictive models and policy recommendations.\n",
    "\n",
    "## Analysis Structure\n",
    "1. Data Loading and Inspection\n",
    "2. Data Cleaning and Preprocessing\n",
    "3. Basic Statistical Analysis\n",
    "4. Distribution Analysis\n",
    "5. Correlation Analysis\n",
    "6. Time Series Patterns\n",
    "7. Feature Analysis\n",
    "8. Visual Storytelling and Insights\n",
    "\n",
    "Each section includes detailed explanations of the steps taken, their purpose, and the insights gained from the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Set up plotting styles\n",
    "plt.style.use('seaborn')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Configure pandas display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Inspection\n",
    "\n",
    "In this section, we will:\n",
    "1. Load the dataset\n",
    "2. Examine the basic structure (shape, columns, data types)\n",
    "3. Check for missing values\n",
    "4. Display sample records\n",
    "5. Generate basic information about the dataset\n",
    "\n",
    "This initial inspection helps us understand the data quality and structure before proceeding with detailed analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "# Note: Update the path to match your dataset location\n",
    "df = pd.read_csv('hotel_data.csv')\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(\"Dataset Shape:\", df.shape)\n",
    "print(\"\\nColumns:\", df.columns.tolist())\n",
    "print(\"\\nData Types:\")\n",
    "print(df.dtypes)\n",
    "print(\"\\nMissing Values:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Display first few rows of the dataset\n",
    "print(\"\\nSample Records:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Cleaning and Preprocessing\n",
    "\n",
    "In this section, we will:\n",
    "1. Handle missing values\n",
    "2. Remove duplicates\n",
    "3. Fix data types\n",
    "4. Handle outliers\n",
    "5. Create derived features if needed\n",
    "\n",
    "Each cleaning step will be documented with the rationale behind the decision and its impact on the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates\n",
    "print(\"Number of duplicate rows:\", df.duplicated().sum())\n",
    "\n",
    "# Handle missing values\n",
    "print(\"\\nHandling missing values:\")\n",
    "for column in df.columns:\n",
    "    missing = df[column].isnull().sum()\n",
    "    if missing > 0:\n",
    "        print(f\"\\n{column}:\")\n",
    "        print(f\"Missing values: {missing}\")\n",
    "        if df[column].dtype in ['int64', 'float64']:\n",
    "            # For numerical columns, fill with median\n",
    "            df[column].fillna(df[column].median(), inplace=True)\n",
    "            print(\"Filled with median\")\n",
    "        else:\n",
    "            # For categorical columns, fill with mode\n",
    "            df[column].fillna(df[column].mode()[0], inplace=True)\n",
    "            print(\"Filled with mode\")\n",
    "\n",
    "# Convert data types if needed\n",
    "# Example: Convert date columns to datetime\n",
    "date_columns = [col for col in df.columns if 'date' in col.lower()]\n",
    "for col in date_columns:\n",
    "    df[col] = pd.to_datetime(df[col])\n",
    "\n",
    "print(\"\\nUpdated Data Types:\")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Basic Statistical Analysis\n",
    "\n",
    "In this section, we will examine:\n",
    "1. Descriptive statistics for numerical variables\n",
    "2. Frequency distributions for categorical variables\n",
    "3. Key summary metrics\n",
    "4. Quartile analysis\n",
    "5. Variance and standard deviation interpretation\n",
    "\n",
    "This analysis will help us understand the central tendencies and variability in our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate descriptive statistics for numerical columns\n",
    "numerical_columns = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "print(\"Descriptive Statistics for Numerical Variables:\")\n",
    "print(df[numerical_columns].describe())\n",
    "\n",
    "# Calculate frequency distributions for categorical columns\n",
    "categorical_columns = df.select_dtypes(include=['object']).columns\n",
    "print(\"\\nFrequency Distributions for Categorical Variables:\")\n",
    "for col in categorical_columns:\n",
    "    print(f\"\\n{col}:\")\n",
    "    print(df[col].value_counts(normalize=True).nlargest(10))\n",
    "\n",
    "# Create a summary visualization of key metrics\n",
    "plt.figure(figsize=(15, 6))\n",
    "sns.boxplot(data=df[numerical_columns])\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('Distribution of Numerical Variables')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Distribution Analysis\n",
    "\n",
    "This section explores:\n",
    "1. Distribution shapes for numerical variables\n",
    "2. Identification of outliers\n",
    "3. Skewness and kurtosis analysis\n",
    "4. Normal distribution tests\n",
    "5. Visual distribution analysis\n",
    "\n",
    "Understanding these distributions will help us identify patterns and anomalies in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create distribution plots for numerical variables\n",
    "for col in numerical_columns:\n",
    "    fig = make_subplots(rows=1, cols=2,\n",
    "                       subplot_titles=[f'Distribution of {col}', f'Box Plot of {col}'])\n",
    "    \n",
    "    # Histogram\n",
    "    fig.add_trace(go.Histogram(x=df[col], name='Distribution'),\n",
    "                 row=1, col=1)\n",
    "    \n",
    "    # Box plot\n",
    "    fig.add_trace(go.Box(y=df[col], name='Box Plot'),\n",
    "                 row=1, col=2)\n",
    "    \n",
    "    # Calculate skewness and kurtosis\n",
    "    skew = stats.skew(df[col].dropna())\n",
    "    kurt = stats.kurtosis(df[col].dropna())\n",
    "    \n",
    "    fig.update_layout(title_text=f'{col} Analysis (Skewness: {skew:.2f}, Kurtosis: {kurt:.2f})',\n",
    "                     height=400, width=900)\n",
    "    fig.show()\n",
    "\n",
    "    # Print summary statistics for outliers\n",
    "    Q1 = df[col].quantile(0.25)\n",
    "    Q3 = df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    outliers = df[(df[col] < (Q1 - 1.5 * IQR)) | (df[col] > (Q3 + 1.5 * IQR))][col]\n",
    "    print(f\"\\nOutliers in {col}:\")\n",
    "    print(f\"Number of outliers: {len(outliers)}\")\n",
    "    print(f\"Percentage of outliers: {(len(outliers)/len(df))*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Correlation Analysis\n",
    "\n",
    "In this section, we will:\n",
    "1. Calculate correlation coefficients between variables\n",
    "2. Create and interpret correlation heatmaps\n",
    "3. Identify strong relationships between variables\n",
    "4. Analyze potential predictors of no-shows\n",
    "5. Visualize key relationships using scatter plots\n",
    "\n",
    "This analysis will help identify which factors might be most important in predicting no-shows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation matrix for numerical variables\n",
    "correlation_matrix = df[numerical_columns].corr()\n",
    "\n",
    "# Create correlation heatmap\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0)\n",
    "plt.title('Correlation Matrix of Numerical Variables')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Identify strong correlations\n",
    "print(\"\\nStrong Correlations (|correlation| > 0.5):\")\n",
    "for i in range(len(correlation_matrix.columns)):\n",
    "    for j in range(i):\n",
    "        if abs(correlation_matrix.iloc[i, j]) > 0.5:\n",
    "            print(f\"{correlation_matrix.columns[i]} vs {correlation_matrix.columns[j]}: {correlation_matrix.iloc[i, j]:.3f}\")\n",
    "\n",
    "# Create scatter plots for highly correlated variables\n",
    "strong_correlations = []\n",
    "for i in range(len(correlation_matrix.columns)):\n",
    "    for j in range(i):\n",
    "        if abs(correlation_matrix.iloc[i, j]) > 0.5:\n",
    "            strong_correlations.append((correlation_matrix.columns[i], correlation_matrix.columns[j]))\n",
    "\n",
    "for var1, var2 in strong_correlations:\n",
    "    fig = px.scatter(df, x=var1, y=var2, \n",
    "                    title=f'Scatter Plot: {var1} vs {var2}',\n",
    "                    trendline=\"ols\")\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Time Series Patterns\n",
    "\n",
    "This section examines:\n",
    "1. Temporal trends in bookings and no-shows\n",
    "2. Seasonal patterns\n",
    "3. Day-of-week effects\n",
    "4. Time-based correlations\n",
    "5. Booking lead time analysis\n",
    "\n",
    "Understanding these temporal patterns can help identify when no-shows are most likely to occur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming we have a date column, let's analyze temporal patterns\n",
    "# Note: Adjust column names based on your actual data\n",
    "\n",
    "# Convert date column to datetime if needed\n",
    "date_col = [col for col in df.columns if 'date' in col.lower()][0]\n",
    "df[date_col] = pd.to_datetime(df[date_col])\n",
    "\n",
    "# Add derived time features\n",
    "df['day_of_week'] = df[date_col].dt.day_name()\n",
    "df['month'] = df[date_col].dt.month\n",
    "df['year'] = df[date_col].dt.year\n",
    "\n",
    "# Daily no-show rate over time\n",
    "daily_noshows = df.groupby(date_col)['no_show'].mean()\n",
    "\n",
    "# Plot time series of no-show rate\n",
    "fig = px.line(daily_noshows, \n",
    "              title='Daily No-Show Rate Over Time',\n",
    "              labels={'value': 'No-Show Rate', 'date': 'Date'})\n",
    "fig.show()\n",
    "\n",
    "# No-show rate by day of week\n",
    "dow_noshows = df.groupby('day_of_week')['no_show'].agg(['mean', 'count'])\n",
    "fig = px.bar(dow_noshows, \n",
    "             title='No-Show Rate by Day of Week',\n",
    "             labels={'day_of_week': 'Day of Week', 'mean': 'No-Show Rate'})\n",
    "fig.show()\n",
    "\n",
    "# Monthly patterns\n",
    "monthly_noshows = df.groupby('month')['no_show'].mean()\n",
    "fig = px.line(monthly_noshows, \n",
    "              title='Monthly No-Show Rate',\n",
    "              labels={'value': 'No-Show Rate', 'month': 'Month'})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Feature Analysis\n",
    "\n",
    "This section focuses on:\n",
    "1. Individual feature importance\n",
    "2. Feature interactions\n",
    "3. Category distributions\n",
    "4. Feature engineering opportunities\n",
    "5. Potential predictive power of each variable\n",
    "\n",
    "This analysis will help identify which features are most likely to be useful in predicting no-shows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze categorical variables\n",
    "for col in categorical_columns:\n",
    "    if col != 'no_show':  # Exclude target variable if it's categorical\n",
    "        # Create a contingency table\n",
    "        contingency = pd.crosstab(df[col], df['no_show'], normalize='index')\n",
    "        \n",
    "        # Plot relationship with no-show rate\n",
    "        fig = px.bar(contingency, \n",
    "                    title=f'No-Show Rate by {col}',\n",
    "                    labels={'index': col, 'value': 'No-Show Rate'})\n",
    "        fig.show()\n",
    "        \n",
    "        # Chi-square test of independence\n",
    "        chi2, p_value = stats.chi2_contingency(pd.crosstab(df[col], df['no_show']))[0:2]\n",
    "        print(f\"\\nChi-square test for {col}:\")\n",
    "        print(f\"Chi-square statistic: {chi2:.2f}\")\n",
    "        print(f\"p-value: {p_value:.4f}\")\n",
    "\n",
    "# Analyze numerical variables\n",
    "for col in numerical_columns:\n",
    "    if col != 'no_show':  # Exclude target variable if it's numerical\n",
    "        # Compare distributions for no-show vs show\n",
    "        fig = px.box(df, x='no_show', y=col,\n",
    "                    title=f'Distribution of {col} by No-Show Status')\n",
    "        fig.show()\n",
    "        \n",
    "        # T-test between no-show and show groups\n",
    "        show = df[df['no_show'] == 0][col].dropna()\n",
    "        noshow = df[df['no_show'] == 1][col].dropna()\n",
    "        t_stat, p_value = stats.ttest_ind(show, noshow)\n",
    "        print(f\"\\nT-test for {col}:\")\n",
    "        print(f\"T-statistic: {t_stat:.2f}\")\n",
    "        print(f\"p-value: {p_value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Visual Storytelling and Key Insights\n",
    "\n",
    "This final section synthesizes our findings into a coherent narrative:\n",
    "1. Key patterns and trends identified\n",
    "2. Most significant factors influencing no-shows\n",
    "3. Potential areas for policy intervention\n",
    "4. Recommendations for feature engineering\n",
    "5. Summary of insights for predictive modeling\n",
    "\n",
    "These insights will directly inform our machine learning approach and policy recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a summary dashboard of key metrics\n",
    "fig = make_subplots(\n",
    "    rows=2, cols=2,\n",
    "    subplot_titles=('Overall No-Show Rate',\n",
    "                   'No-Shows by Day of Week',\n",
    "                   'No-Shows by Month',\n",
    "                   'Top Correlating Features')\n",
    ")\n",
    "\n",
    "# Overall no-show rate\n",
    "no_show_rate = df['no_show'].mean()\n",
    "fig.add_trace(\n",
    "    go.Indicator(\n",
    "        mode=\"gauge+number\",\n",
    "        value=no_show_rate * 100,\n",
    "        title={'text': \"No-Show Rate (%)\"},\n",
    "        gauge={'axis': {'range': [0, 100]}},\n",
    "    ),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# No-shows by day of week\n",
    "dow_data = df.groupby('day_of_week')['no_show'].mean().sort_values(ascending=False)\n",
    "fig.add_trace(\n",
    "    go.Bar(x=dow_data.index, y=dow_data.values),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "# No-shows by month\n",
    "monthly_data = df.groupby('month')['no_show'].mean()\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=monthly_data.index, y=monthly_data.values, mode='lines+markers'),\n",
    "    row=2, col=1\n",
    ")\n",
    "\n",
    "# Top correlating features\n",
    "correlations = df.corr()['no_show'].sort_values(ascending=False)\n",
    "top_correlations = correlations[1:6]  # Exclude self-correlation\n",
    "fig.add_trace(\n",
    "    go.Bar(x=top_correlations.index, y=top_correlations.values),\n",
    "    row=2, col=2\n",
    ")\n",
    "\n",
    "fig.update_layout(height=800, title_text=\"Key Insights Dashboard\")\n",
    "fig.show()\n",
    "\n",
    "# Print key findings\n",
    "print(\"\\nKey Findings:\")\n",
    "print(f\"1. Overall no-show rate: {no_show_rate*100:.2f}%\")\n",
    "print(\"\\n2. Top days for no-shows:\")\n",
    "print(dow_data.head().to_string())\n",
    "print(\"\\n3. Top correlating features with no-shows:\")\n",
    "print(top_correlations.to_string())\n",
    "\n",
    "# Summarize potential feature importance\n",
    "print(\"\\nRecommended Features for Modeling:\")\n",
    "for feature in top_correlations.index:\n",
    "    print(f\"- {feature}: correlation = {top_correlations[feature]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions and Next Steps\n",
    "\n",
    "### Key Findings\n",
    "1. Summary of the most significant patterns discovered in the data\n",
    "2. Identification of key factors influencing no-shows\n",
    "3. Temporal patterns that may affect no-show rates\n",
    "4. Important feature interactions discovered\n",
    "\n",
    "### Recommendations for Modeling\n",
    "1. Feature selection recommendations\n",
    "2. Suggested preprocessing steps\n",
    "3. Potential feature engineering opportunities\n",
    "4. Considerations for model selection\n",
    "\n",
    "### Business Implications\n",
    "1. Insights for policy development\n",
    "2. Potential intervention points\n",
    "3. Areas requiring further investigation\n",
    "4. Expected impact on no-show rates\n",
    "\n",
    "The analysis provides a strong foundation for developing predictive models and formulating effective policies to reduce no-show rates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üß™ Exploratory Data Analysis: Hotel No-Show Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üì¶ Imports\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from src.data_loader import load_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üì• Load data\n",
    "df = load_table()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üßæ Basic info\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìä Summary statistics\n",
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîç Missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìà No-show distribution\n",
    "sns.countplot(x='no_show', data=df)\n",
    "plt.title(\"No-Show Distribution\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
